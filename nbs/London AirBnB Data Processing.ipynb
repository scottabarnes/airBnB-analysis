{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London AirBnB Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this notebook is to perform the required data processing for analysis looking at the impact of the global pandemic and lockdown in London on demand for and supply of AirBnB listings. \n",
    "\n",
    "## Methodology\n",
    "The data was downloaded from AirBnB inside data. The directory structure for the datafiles is as follows:\n",
    "- 1-AirBnB-Analysis\n",
    "    - archive - archive of old versions of data files and analysis, included in .gitignore\n",
    "    - nbs - folder containing processing and analysis notebooks\n",
    "    - tmp - temporary directory containing processed data files, included in .gitignore  \n",
    "    - data\n",
    "        - AirBnB-Data-04-09-20 - parent directory of data downloaded\n",
    "            - 2019_07_10 - subdirectories of data downloaded, named based on when data scraped\n",
    "            - 2019_08_09, etc. \n",
    "            \n",
    "The following processing steps are performed: \n",
    "1. Zipped data files are renamed and unzipped\n",
    "2. Calendar and listings data files are processed for subsequent analysis \n",
    "3. Data files are read back as feather format for faster subsequent ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import external libraries required for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, time, timedelta\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import re \n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Hide warnings \n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local library import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find local library directory and import utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Find local library directory - which should be located within a parent directory\n",
    "current_path = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "current_path = os.getcwd() \n",
    "libfiledir = \"library\"\n",
    "\n",
    "current_path\n",
    "direxists = False\n",
    "while direxists==False:\n",
    "    test_dir = os.path.join(current_path,libfiledir)\n",
    "    last_current_path = current_path\n",
    "    direxists = os.path.isdir(test_dir)\n",
    "    current_path = os.path.dirname(current_path)\n",
    "    if(current_path == last_current_path):\n",
    "        break;\n",
    "        \n",
    "if direxists == True:\n",
    "    sys.path.append(test_dir)\n",
    "    \n",
    "\n",
    "# Import utility functions from data frame common\n",
    "from dataframe_common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion / import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of source data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source data is held in the data directory. Data downloaded is for 12 months, from July 2019 to June 2020, and also includes a file containing neighbourhood geographic data. Each folder contains the files that were scraped at that time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2019_07_10\u001b[m\u001b[m         \u001b[34m2019_11_05\u001b[m\u001b[m         \u001b[34m2020_03_15\u001b[m\u001b[m         \u001b[34m2020_08_24\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_08_09\u001b[m\u001b[m         \u001b[34m2019_12_09\u001b[m\u001b[m         \u001b[34m2020_04_14\u001b[m\u001b[m         \u001b[34mNeighbourhood_data\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_09_14\u001b[m\u001b[m         \u001b[34m2020_01_09\u001b[m\u001b[m         \u001b[34m2020_05_10\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_10_15\u001b[m\u001b[m         \u001b[34m2020_02_16\u001b[m\u001b[m         \u001b[34m2020_06_11\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/AirBnB-Data-040920'\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar.csv.gz  listings.csv     listings_det.csv reviews.csv.gz\r\n",
      "calendar_det.csv listings.csv.gz  reviews.csv      reviews_det.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {data_dir}/'2019_07_10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each folder contains 5 files.  \n",
    "- listings.csv - summary information and metrics for listings in London\n",
    "- reviews.csv- summary review data and listing ID for listings in London\n",
    "- calendar.csv.gz - detailed calendar data for listings in London\n",
    "- reviews.csv.gz - detailed review data for listings in London\n",
    "- listings.csv.gz - detailed lilstings data for London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to unzipping the required files is to create a list with the sub-directories containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019_07_10',\n",
       " '2019_08_09',\n",
       " '2019_09_14',\n",
       " '2019_10_15',\n",
       " '2019_11_05',\n",
       " '2019_12_09',\n",
       " '2020_01_09',\n",
       " '2020_02_16',\n",
       " '2020_03_15',\n",
       " '2020_04_14',\n",
       " '2020_05_10',\n",
       " '2020_06_11',\n",
       " '2020_08_24']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs = !ls {data_dir}\n",
    "sub_dirs.remove('Neighbourhood_data')\n",
    "sub_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will iterate through the subdirectories and the zipped files, and first rename them (so they are distinguishable from the non-zipped files) and then unzip in the same location. If the unzipped file is already in the directory, that will be passed over. \n",
    "\n",
    "The function will skip onto the next directory if the unzipped file is already in the sub-directory (i.e. it has already been run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(periods):\n",
    "    ''' Takes in list of subdirectories data and copies, renames and unzips .gz files'''    \n",
    "    file_names = ['calendar','listings','reviews']\n",
    "    for period in periods:\n",
    "        sub_dir_files = ! ls {data_dir}/{period}\n",
    "        print(f'Unzipping files in subdirectory {period}')\n",
    "        for file_name in file_names:\n",
    "            if file_name + '_det.csv' in sub_dir_files:\n",
    "                print(f'   Already unzipped {file_name}')\n",
    "                pass\n",
    "            else:\n",
    "                print(f'   Copying and renaming {file_name}')\n",
    "                cur_file_path = os.path.join(data_dir,period,file_name + '.csv.gz')\n",
    "                new_file_path = os.path.join(data_dir,period,file_name + '_det.csv.gz')\n",
    "                ! cp {cur_file_path} {new_file_path}    \n",
    "                ! gunzip {new_file_path}\n",
    "                print(f'   Unzipped copied file {file_name}') \n",
    "    print('Looped through all sub-directories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping files in subdirectory 2019_07_10\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2019_08_09\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2019_09_14\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2019_10_15\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2019_11_05\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2019_12_09\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_01_09\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_02_16\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_03_15\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_04_14\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_05_10\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_06_11\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Unzipping files in subdirectory 2020_08_24\n",
      "   Already unzipped calendar\n",
      "   Already unzipped listings\n",
      "   Already unzipped reviews\n",
      "Looped through all sub-directories\n"
     ]
    }
   ],
   "source": [
    "unzip_data(sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion and processing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now unzipped, the data can be ingested and processed for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed calendar data (unzipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calendar data contains daily price and stay information for each listing. The price fields are formatted with special characters and so these need to be removed. The date field is currently at a daily level, and will be used to create date_month and date_year features.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2019_07_10\u001b[m\u001b[m         \u001b[34m2019_11_05\u001b[m\u001b[m         \u001b[34m2020_03_15\u001b[m\u001b[m         \u001b[34m2020_08_24\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_08_09\u001b[m\u001b[m         \u001b[34m2019_12_09\u001b[m\u001b[m         \u001b[34m2020_04_14\u001b[m\u001b[m         \u001b[34mNeighbourhood_data\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_09_14\u001b[m\u001b[m         \u001b[34m2020_01_09\u001b[m\u001b[m         \u001b[34m2020_05_10\u001b[m\u001b[m\r\n",
      "\u001b[34m2019_10_15\u001b[m\u001b[m         \u001b[34m2020_02_16\u001b[m\u001b[m         \u001b[34m2020_06_11\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43737744,2021-06-03,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-04,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-05,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-06,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-07,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-08,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-09,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-10,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-11,t,$83.00,$83.00,730,1125\r\n",
      "43737744,2021-06-12,t,$83.00,$83.00,730,1125\r\n"
     ]
    }
   ],
   "source": [
    "file_name = 'calendar_det.csv'\n",
    "! tail {os.path.join(data_dir,'2020_06_11','calendar_det.csv')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created to clean the calendar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_calendar(calendar):\n",
    "    ''' Takes in an unprocessed calendar file and cleans the prices cols and adds date flags'''\n",
    "    calendar['date_month'] = calendar['date'].dt.month\n",
    "    calendar['date_year'] = calendar['date'].dt.year\n",
    "    calendar['price']  = calendar['price'].str.replace(\"$\",\"\")\n",
    "    calendar['price']  = calendar['price'].str.replace(\",\",\"\")\n",
    "    calendar['price'] = calendar['price'].astype(float)\n",
    "    calendar['available'] = np.where(calendar['available']==\"t\",1,0)\n",
    "    return calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed data files will be stored within a temporary directory. Files currnetly in the temporary directory will be held within a list so files aren't unnecessarily processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = 'tmp'\n",
    "processed_data = 'processed_data'\n",
    "# os.mkdir(os.path.join(tmp_dir,processed_data))\n",
    "tmp_dir_files = ! ls {tmp_dir}/{processed_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019_07_10',\n",
       " '2019_08_09',\n",
       " '2019_09_14',\n",
       " '2019_10_15',\n",
       " '2019_11_05',\n",
       " '2019_12_09',\n",
       " '2020_01_09',\n",
       " '2020_02_16',\n",
       " '2020_03_15',\n",
       " '2020_04_14',\n",
       " '2020_05_10',\n",
       " '2020_06_11',\n",
       " '2020_08_24']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_07_10calendar_det.feather'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = '2019_07_10'\n",
    "file_name = 'calendar_det.csv'\n",
    "updated_file_name = period + file_name.replace(\".csv\", \".feather\")\n",
    "updated_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function is created to read and clean the calendar dataframe, and finally save it back to the temporary directory. The read in dataframe is deleted to reduce memory required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_calendars(periods):\n",
    "    ''' Takes in a list of sub-directories and iteratively cleans and saves the calendar file in them '''\n",
    "    for period in periods:\n",
    "        print(f'Processing calendar dataframe from {period}...')\n",
    "        updated_file_name = period + file_name.replace(\".csv\", \".feather\")\n",
    "        if updated_file_name in tmp_dir_files:\n",
    "            print(f'    data already processed for this period.')\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                df  = pd.read_csv(os.path.join(data_dir,period,file_name))\n",
    "                print(\"   1. df read in\")\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "                df  = clean_calendar(df)\n",
    "                print(\"   2. df cleaned\")\n",
    "                df.to_feather(os.path.join(tmp_dir,processed_data,updated_file_name))\n",
    "                print(\"   3. df renamed and outputted to feather\")\n",
    "                del df\n",
    "                print(\"   4. df deleted from memory\")            \n",
    "            except MemoryError:\n",
    "                print('Memory error')\n",
    "            else:\n",
    "                print(f'Processed calendar dataframe from {period}')\n",
    "    print('Function complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function is executed to work through all sub directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing calendar dataframe from 2019_07_10...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2019_08_09...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2019_09_14...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2019_10_15...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2019_11_05...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2019_12_09...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_01_09...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_02_16...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_03_15...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_04_14...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_05_10...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_06_11...\n",
      "    data already processed for this period.\n",
      "Processing calendar dataframe from 2020_08_24...\n",
      "    data already processed for this period.\n",
      "Function complete\n",
      "CPU times: user 1.07 ms, sys: 684 Âµs, total: 1.75 ms\n",
      "Wall time: 1.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read_and_clean_calendars(sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary directory now contains a sub-directory with the processed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_07_10calendar_det.feather 2020_02_16listings.feather\r\n",
      "2019_07_10listings.feather     2020_03_15calendar_det.feather\r\n",
      "2019_08_09calendar_det.feather 2020_03_15listings.feather\r\n",
      "2019_08_09listings.feather     2020_04_14calendar_det.feather\r\n",
      "2019_09_14calendar_det.feather 2020_04_14listings.feather\r\n",
      "2019_09_14listings.feather     2020_05_10calendar_det.feather\r\n",
      "2019_10_15calendar_det.feather 2020_05_10listings.feather\r\n",
      "2019_10_15listings.feather     2020_06_11calendar_det.feather\r\n",
      "2019_11_05calendar_det.feather 2020_06_11listings.feather\r\n",
      "2019_11_05listings.feather     2020_08_24calendar_det.feather\r\n",
      "2019_12_09calendar_det.feather 2020_08_24listings.feather\r\n",
      "2019_12_09listings.feather     all_listings.csv\r\n",
      "2020_01_09calendar_det.feather all_listings.feather\r\n",
      "2020_01_09listings.feather     all_listings_price.feather\r\n",
      "2020_02_16calendar_det.feather list_price_avail_grped.feather\r\n"
     ]
    }
   ],
   "source": [
    "! ls {tmp_dir}/{processed_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed file contains the added date feature columns and cleaned price columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "      <th>adjusted_price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208952</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>$263.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81951</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>$190.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81951</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>$190.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81951</td>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>$190.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81951</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>$190.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       date  available  price adjusted_price  minimum_nights  \\\n",
       "0      208952 2020-08-26          0  263.0        $263.00             2.0   \n",
       "1       81951 2020-08-27          0  190.0        $190.00             5.0   \n",
       "2       81951 2020-08-28          1  190.0        $190.00             5.0   \n",
       "3       81951 2020-08-29          1  190.0        $190.00             5.0   \n",
       "4       81951 2020-08-30          1  190.0        $190.00             5.0   \n",
       "\n",
       "   maximum_nights  date_month  date_year  \n",
       "0            30.0           8       2020  \n",
       "1            10.0           8       2020  \n",
       "2            10.0           8       2020  \n",
       "3            10.0           8       2020  \n",
       "4            10.0           8       2020  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.read_feather(os.path.join(tmp_dir,processed_data,'2020_08_24calendar_det.feather'))\n",
    "example_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listings data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listing data contains summary information for metrics for listings in London. For the analysis only ID, room type and calculated host listing count are required from these files for segmentation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,name,host_id,host_name,neighbourhood_group,neighbourhood,latitude,longitude,room_type,price,minimum_nights,number_of_reviews,last_review,reviews_per_month,calculated_host_listings_count,availability_365\r\n",
      "11551,Arty and Bright London Apartment in Zone 2,43039,Adriano,,Lambeth,51.46225,-0.11732,Entire home/apt,88,2,192,2020-03-26,1.54,2,347\r\n",
      "13913,Holiday London DB Room Let-on going,54730,Alina,,Islington,51.56802,-0.11121,Private room,65,1,21,2020-02-22,0.18,3,347\r\n",
      "15400,Bright Chelsea  Apartment. Chelsea!,60302,Philippa,,Kensington and Chelsea,51.48796,-0.16898,Entire home/apt,100,10,89,2020-03-16,0.70,1,288\r\n",
      "17402,Superb 3-Bed/2 Bath & Wifi: Trendy W1,67564,Liz,,Westminster,51.52195,-0.14094,Entire home/apt,300,3,42,2019-11-02,0.37,15,326\r\n"
     ]
    }
   ],
   "source": [
    "file_name = 'listings.csv'\n",
    "! head -n 5 {os.path.join(data_dir,'2020_06_11',file_name)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function is created to read and clean the listing dataframe, and finally save it back to the temporary directory. The read in dataframe is deleted to reduce memory required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_listing_info(periods):\n",
    "    ''' Reads and cleans the listings dataframe and saves it back to the temporary directory'''\n",
    "    for period in periods:\n",
    "        print(f'Processing listing dataframe from {period}...')\n",
    "        updated_file_name = period + file_name.replace(\".csv\",\".feather\")\n",
    "        if updated_file_name in tmp_dir_files:\n",
    "            print(f'    data already processed for this period.')\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                df  = pd.read_csv(os.path.join(data_dir,period,file_name)\n",
    "                                 ,usecols=['id','room_type','calculated_host_listings_count'])\n",
    "                print(\"   1. df read in\")\n",
    "                df.rename(columns={'id':'listing_id'},inplace=True)\n",
    "                print(\"   2. renamed columns\")\n",
    "                df.to_feather(os.path.join(tmp_dir,processed_data,updated_file_name))\n",
    "                print(\"   3. df renamed and outputted to feather\")\n",
    "                del df\n",
    "                print(\"   4. df deleted from memory\")            \n",
    "            except MemoryError:\n",
    "                print('Memory error')\n",
    "            else:\n",
    "                print(f'Processed calendar dataframe from {period}')\n",
    "    print('Function complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing listing dataframe from 2019_07_10...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2019_08_09...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2019_09_14...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2019_10_15...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2019_11_05...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2019_12_09...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_01_09...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_02_16...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_03_15...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_04_14...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_05_10...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_06_11...\n",
      "    data already processed for this period.\n",
      "Processing listing dataframe from 2020_08_24...\n",
      "    data already processed for this period.\n",
      "Function complete\n"
     ]
    }
   ],
   "source": [
    "read_in_listing_info(sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary directory now contains a sub-directory with the processed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_07_10calendar_det.feather 2020_02_16listings.feather\r\n",
      "2019_07_10listings.feather     2020_03_15calendar_det.feather\r\n",
      "2019_08_09calendar_det.feather 2020_03_15listings.feather\r\n",
      "2019_08_09listings.feather     2020_04_14calendar_det.feather\r\n",
      "2019_09_14calendar_det.feather 2020_04_14listings.feather\r\n",
      "2019_09_14listings.feather     2020_05_10calendar_det.feather\r\n",
      "2019_10_15calendar_det.feather 2020_05_10listings.feather\r\n",
      "2019_10_15listings.feather     2020_06_11calendar_det.feather\r\n",
      "2019_11_05calendar_det.feather 2020_06_11listings.feather\r\n",
      "2019_11_05listings.feather     2020_08_24calendar_det.feather\r\n",
      "2019_12_09calendar_det.feather 2020_08_24listings.feather\r\n",
      "2019_12_09listings.feather     all_listings.csv\r\n",
      "2020_01_09calendar_det.feather all_listings.feather\r\n",
      "2020_01_09listings.feather     all_listings_price.feather\r\n",
      "2020_02_16calendar_det.feather list_price_avail_grped.feather\r\n"
     ]
    }
   ],
   "source": [
    "! ls {tmp_dir}/{processed_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>room_type</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11551</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13913</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15400</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17402</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17506</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        room_type  calculated_host_listings_count\n",
       "0       11551  Entire home/apt                               2\n",
       "1       13913     Private room                               3\n",
       "2       15400  Entire home/apt                               1\n",
       "3       17402  Entire home/apt                              14\n",
       "4       17506     Private room                               2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.read_feather(os.path.join(tmp_dir,processed_data,'2020_08_24listings.feather'))\n",
    "example_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
